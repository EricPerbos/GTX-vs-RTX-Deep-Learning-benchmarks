{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.tracker import *\n",
    "from fastai.vision.models.wrn import wrn_22\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Init27 notebook, a generic training with \n",
    "#https://github.com/EricPerbos/RTX-2080Ti-Vs-GTX-1080Ti-CIFAR-100-Benchmarks/blob/master/1080Ti%20Notebook.ipynb\n",
    "\n",
    "import functools\n",
    "import traceback\n",
    "def get_ref_free_exc_info():\n",
    "    \"Free traceback from references to locals/globals to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n",
    "    type, val, tb = sys.exc_info()\n",
    "    traceback.clear_frames(tb)\n",
    "    return (type, val, tb)\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = get_ref_free_exc_info() # must!\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_mem_restore_ctx():\n",
    "    \" context manager to reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    def __enter__(self): return self\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if not exc_val: return True\n",
    "        traceback.clear_frames(exc_tb)\n",
    "        raise exc_type(exc_val).with_traceback(exc_tb) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/eric/Link_fastaiV1/data/cifar10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.CIFAR)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 18 in FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet18, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 09:18\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.200201    1.770271    0.387200  (00:10)\n",
      "2      1.873866    1.563576    0.458600  (00:09)\n",
      "3      1.660982    1.422434    0.501100  (00:09)\n",
      "4      1.505127    1.311411    0.533300  (00:09)\n",
      "5      1.369722    1.225595    0.563500  (00:08)\n",
      "6      1.275731    1.140750    0.590400  (00:09)\n",
      "7      1.194634    1.080315    0.621100  (00:09)\n",
      "8      1.123352    1.019682    0.642200  (00:09)\n",
      "9      1.075948    0.969278    0.659500  (00:09)\n",
      "10     1.027185    0.938903    0.669800  (00:09)\n",
      "11     0.992491    0.893126    0.683300  (00:09)\n",
      "12     0.959926    0.868093    0.695300  (00:09)\n",
      "13     0.929484    0.841902    0.702600  (00:09)\n",
      "14     0.898935    0.824227    0.708000  (00:09)\n",
      "15     0.887263    0.809403    0.716600  (00:09)\n",
      "16     0.858852    0.788126    0.719500  (00:09)\n",
      "17     0.845001    0.776555    0.729900  (00:09)\n",
      "18     0.824738    0.769374    0.728700  (00:09)\n",
      "19     0.820285    0.766737    0.728100  (00:09)\n",
      "20     0.800344    0.754552    0.737100  (00:09)\n",
      "21     0.791273    0.744932    0.737100  (00:09)\n",
      "22     0.771907    0.731905    0.743900  (00:09)\n",
      "23     0.765269    0.743180    0.740200  (00:09)\n",
      "24     0.761304    0.714111    0.749300  (00:09)\n",
      "25     0.747512    0.711858    0.750300  (00:09)\n",
      "26     0.746752    0.709016    0.750800  (00:09)\n",
      "27     0.740665    0.705075    0.754200  (00:09)\n",
      "28     0.731482    0.697381    0.757200  (00:09)\n",
      "29     0.723383    0.694941    0.760100  (00:09)\n",
      "30     0.718549    0.681105    0.762500  (00:09)\n",
      "31     0.713530    0.680434    0.761100  (00:09)\n",
      "32     0.715660    0.685482    0.760900  (00:09)\n",
      "33     0.702584    0.684598    0.761200  (00:09)\n",
      "34     0.696593    0.678988    0.764000  (00:09)\n",
      "35     0.692655    0.677266    0.764100  (00:09)\n",
      "36     0.693181    0.666779    0.767200  (00:09)\n",
      "37     0.678933    0.666832    0.766900  (00:09)\n",
      "38     0.678849    0.663341    0.766500  (00:09)\n",
      "39     0.677007    0.661424    0.768900  (00:09)\n",
      "40     0.683600    0.661551    0.768000  (00:09)\n",
      "41     0.671118    0.658864    0.770500  (00:09)\n",
      "42     0.663476    0.661151    0.770700  (00:09)\n",
      "43     0.660407    0.656842    0.772300  (00:09)\n",
      "44     0.653901    0.659884    0.771800  (00:09)\n",
      "45     0.653678    0.656292    0.771000  (00:08)\n",
      "46     0.654373    0.657645    0.770800  (00:09)\n",
      "47     0.653983    0.655145    0.770200  (00:09)\n",
      "48     0.645581    0.652260    0.771400  (00:09)\n",
      "49     0.649843    0.654956    0.770300  (00:09)\n",
      "50     0.646761    0.651288    0.773000  (00:08)\n",
      "51     0.640894    0.649251    0.775600  (00:09)\n",
      "52     0.646066    0.651899    0.775200  (00:09)\n",
      "53     0.640090    0.651132    0.772500  (00:09)\n",
      "54     0.645131    0.651132    0.772800  (00:09)\n",
      "55     0.641221    0.650073    0.774200  (00:09)\n",
      "56     0.643171    0.649096    0.773700  (00:09)\n",
      "57     0.639798    0.650962    0.774700  (00:09)\n",
      "58     0.637130    0.650749    0.774400  (00:09)\n",
      "59     0.632796    0.650482    0.774200  (00:09)\n",
      "60     0.636783    0.650307    0.772800  (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 18 in FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet18, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 09:05\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.218122    1.786876    0.378600  (00:10)\n",
      "2      1.882517    1.572523    0.451000  (00:08)\n",
      "3      1.666607    1.420917    0.499100  (00:08)\n",
      "4      1.501447    1.308564    0.533800  (00:09)\n",
      "5      1.381089    1.221739    0.564000  (00:09)\n",
      "6      1.273666    1.147675    0.587600  (00:09)\n",
      "7      1.190675    1.079463    0.616000  (00:09)\n",
      "8      1.128813    1.028087    0.633300  (00:09)\n",
      "9      1.072469    0.975964    0.654600  (00:09)\n",
      "10     1.024608    0.937199    0.668500  (00:08)\n",
      "11     0.984324    0.899542    0.684700  (00:09)\n",
      "12     0.949098    0.871396    0.689500  (00:09)\n",
      "13     0.929929    0.849434    0.700000  (00:08)\n",
      "14     0.899533    0.828132    0.710900  (00:09)\n",
      "15     0.880750    0.807545    0.716400  (00:09)\n",
      "16     0.859833    0.804393    0.715800  (00:08)\n",
      "17     0.842105    0.775370    0.725900  (00:09)\n",
      "18     0.830966    0.767316    0.728600  (00:09)\n",
      "19     0.814234    0.751041    0.733200  (00:09)\n",
      "20     0.803363    0.755358    0.732500  (00:09)\n",
      "21     0.786103    0.734311    0.740500  (00:08)\n",
      "22     0.771683    0.730549    0.741400  (00:09)\n",
      "23     0.767522    0.723558    0.743600  (00:09)\n",
      "24     0.756106    0.709131    0.749700  (00:09)\n",
      "25     0.752602    0.709253    0.748200  (00:09)\n",
      "26     0.744187    0.702243    0.753600  (00:09)\n",
      "27     0.736445    0.696889    0.751100  (00:09)\n",
      "28     0.730265    0.698842    0.754900  (00:09)\n",
      "29     0.721252    0.690169    0.757000  (00:09)\n",
      "30     0.717951    0.694386    0.755900  (00:09)\n",
      "31     0.709760    0.679190    0.762400  (00:09)\n",
      "32     0.708333    0.683201    0.758400  (00:09)\n",
      "33     0.710001    0.678538    0.762400  (00:09)\n",
      "34     0.697353    0.671214    0.766900  (00:09)\n",
      "35     0.690161    0.672389    0.767000  (00:09)\n",
      "36     0.686389    0.664851    0.766800  (00:09)\n",
      "37     0.684673    0.665090    0.765900  (00:09)\n",
      "38     0.681628    0.670184    0.765700  (00:09)\n",
      "39     0.679065    0.662830    0.765900  (00:08)\n",
      "40     0.669432    0.661557    0.765700  (00:09)\n",
      "41     0.669215    0.661803    0.766800  (00:09)\n",
      "42     0.667405    0.658125    0.770200  (00:09)\n",
      "43     0.660112    0.653932    0.768100  (00:09)\n",
      "44     0.655991    0.656297    0.769300  (00:09)\n",
      "45     0.656155    0.655687    0.772300  (00:08)\n",
      "46     0.647854    0.650197    0.773500  (00:09)\n",
      "47     0.651433    0.651738    0.774600  (00:09)\n",
      "48     0.645524    0.651747    0.772000  (00:09)\n",
      "49     0.641650    0.648855    0.774500  (00:09)\n",
      "50     0.646116    0.648087    0.775800  (00:09)\n",
      "51     0.642796    0.649542    0.771800  (00:09)\n",
      "52     0.634670    0.647134    0.773400  (00:09)\n",
      "53     0.641573    0.647242    0.773200  (00:09)\n",
      "54     0.636508    0.648239    0.772800  (00:09)\n",
      "55     0.637758    0.647557    0.774000  (00:09)\n",
      "56     0.640713    0.645884    0.775600  (00:09)\n",
      "57     0.634293    0.646878    0.773600  (00:09)\n",
      "58     0.634243    0.648384    0.772600  (00:09)\n",
      "59     0.632827    0.647262    0.772800  (00:09)\n",
      "60     0.632073    0.647095    0.774000  (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet_22 in FP32\n",
    "https://docs.fast.ai/vision.models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, wrn_22(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 45:37\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.536300    1.470832    0.462300  (00:52)\n",
      "2      1.160262    1.107029    0.602500  (00:47)\n",
      "3      0.928368    0.914776    0.679100  (00:47)\n",
      "4      0.760256    0.931047    0.685600  (00:47)\n",
      "5      0.652168    1.042342    0.677400  (00:47)\n",
      "6      0.568983    0.951829    0.694600  (00:46)\n",
      "7      0.507437    1.096947    0.672100  (00:45)\n",
      "8      0.472213    1.027268    0.697300  (00:45)\n",
      "9      0.430894    0.765118    0.775200  (00:45)\n",
      "10     0.397878    0.559144    0.819000  (00:45)\n",
      "11     0.378650    0.499458    0.839700  (00:45)\n",
      "12     0.349510    0.528496    0.829800  (00:45)\n",
      "13     0.331769    0.611600    0.810800  (00:45)\n",
      "14     0.315343    0.511550    0.840100  (00:45)\n",
      "15     0.289794    0.543875    0.838100  (00:45)\n",
      "16     0.281369    0.585915    0.826900  (00:45)\n",
      "17     0.268900    0.399356    0.877100  (00:45)\n",
      "18     0.253308    0.520942    0.848000  (00:45)\n",
      "19     0.226497    0.461053    0.867800  (00:45)\n",
      "20     0.213416    0.415663    0.867800  (00:45)\n",
      "21     0.201284    0.390581    0.873500  (00:45)\n",
      "22     0.179582    0.352270    0.891900  (00:45)\n",
      "23     0.163700    0.354983    0.892900  (00:45)\n",
      "24     0.148280    0.379339    0.894200  (00:45)\n",
      "25     0.138918    0.353311    0.901100  (00:45)\n",
      "26     0.128041    0.372888    0.893300  (00:45)\n",
      "27     0.115707    0.365442    0.896500  (00:45)\n",
      "28     0.104205    0.384074    0.899700  (00:45)\n",
      "29     0.100219    0.349906    0.907200  (00:45)\n",
      "30     0.084279    0.298216    0.916100  (00:45)\n",
      "31     0.076209    0.398091    0.894800  (00:45)\n",
      "32     0.067926    0.369086    0.909200  (00:45)\n",
      "33     0.060201    0.335411    0.915300  (00:45)\n",
      "34     0.056170    0.342336    0.918600  (00:45)\n",
      "35     0.048794    0.325427    0.920500  (00:45)\n",
      "36     0.040708    0.427304    0.905300  (00:45)\n",
      "37     0.042460    0.378450    0.915200  (00:45)\n",
      "38     0.031566    0.325756    0.926400  (00:45)\n",
      "39     0.029164    0.350886    0.922300  (00:45)\n",
      "40     0.027708    0.351130    0.922300  (00:45)\n",
      "41     0.022740    0.338828    0.928200  (00:45)\n",
      "42     0.018385    0.356784    0.929200  (00:45)\n",
      "43     0.015610    0.352012    0.928000  (00:45)\n",
      "44     0.013370    0.347628    0.928700  (00:45)\n",
      "45     0.013069    0.374245    0.927700  (00:45)\n",
      "46     0.009111    0.340720    0.935500  (00:45)\n",
      "47     0.007105    0.335120    0.935000  (00:45)\n",
      "48     0.008293    0.347154    0.934700  (00:45)\n",
      "49     0.006150    0.327534    0.938600  (00:45)\n",
      "50     0.004118    0.340428    0.935900  (00:45)\n",
      "51     0.004096    0.337888    0.937400  (00:45)\n",
      "52     0.002859    0.329441    0.939800  (00:45)\n",
      "53     0.002730    0.331535    0.940500  (00:45)\n",
      "54     0.001624    0.326643    0.938800  (00:45)\n",
      "55     0.001386    0.329346    0.939500  (00:45)\n",
      "56     0.001189    0.331092    0.938900  (00:45)\n",
      "57     0.000939    0.328881    0.940300  (00:45)\n",
      "58     0.001112    0.328323    0.940400  (00:45)\n",
      "59     0.001092    0.329400    0.940200  (00:45)\n",
      "60     0.000794    0.328846    0.941000  (00:45)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet_22 in FP16 (Mixed-Precision)\n",
    "https://docs.fast.ai/vision.models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, wrn_22(), metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 40:45\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.688091    1.504960    0.440300  (00:47)\n",
      "2      1.332519    1.226433    0.563000  (00:40)\n",
      "3      1.078594    1.116559    0.606400  (00:40)\n",
      "4      0.899793    0.842620    0.706200  (00:40)\n",
      "5      0.755262    0.869375    0.697700  (00:40)\n",
      "6      0.649841    1.110025    0.670800  (00:40)\n",
      "7      0.575567    0.794060    0.738400  (00:40)\n",
      "8      0.513926    0.790122    0.742900  (00:40)\n",
      "9      0.471724    0.787445    0.752700  (00:40)\n",
      "10     0.430403    1.031972    0.711800  (00:40)\n",
      "11     0.405307    0.680322    0.779800  (00:40)\n",
      "12     0.379110    0.650501    0.789000  (00:40)\n",
      "13     0.355727    0.721022    0.780000  (00:40)\n",
      "14     0.334592    0.677938    0.788400  (00:40)\n",
      "15     0.321955    0.880525    0.743300  (00:40)\n",
      "16     0.306603    0.427979    0.860000  (00:40)\n",
      "17     0.283275    0.987854    0.756600  (00:40)\n",
      "18     0.271497    0.671504    0.802000  (00:40)\n",
      "19     0.260273    0.483802    0.850600  (00:40)\n",
      "20     0.235744    0.525812    0.839500  (00:40)\n",
      "21     0.218420    0.447830    0.860800  (00:40)\n",
      "22     0.199778    0.432521    0.868800  (00:40)\n",
      "23     0.184060    0.532307    0.847700  (00:40)\n",
      "24     0.174738    0.388026    0.884900  (00:40)\n",
      "25     0.156409    0.463365    0.861100  (00:40)\n",
      "26     0.146124    0.317091    0.906700  (00:40)\n",
      "27     0.127893    0.417648    0.888300  (00:40)\n",
      "28     0.119124    0.368942    0.892200  (00:40)\n",
      "29     0.115547    0.331973    0.905400  (00:40)\n",
      "30     0.098657    0.280384    0.917500  (00:40)\n",
      "31     0.088734    0.403816    0.894400  (00:40)\n",
      "32     0.088737    0.319037    0.912500  (00:40)\n",
      "33     0.077457    0.287044    0.923900  (00:40)\n",
      "34     0.067676    0.402044    0.899000  (00:40)\n",
      "35     0.064022    0.317274    0.919100  (00:40)\n",
      "36     0.054523    0.334640    0.914100  (00:40)\n",
      "37     0.048460    0.306747    0.925700  (00:40)\n",
      "38     0.041419    0.340623    0.920900  (00:40)\n",
      "39     0.038921    0.317976    0.926000  (00:40)\n",
      "40     0.032069    0.337138    0.925500  (00:40)\n",
      "41     0.027273    0.329799    0.929200  (00:40)\n",
      "42     0.027216    0.310514    0.932000  (00:40)\n",
      "43     0.025027    0.329543    0.924800  (00:40)\n",
      "44     0.018410    0.329949    0.932200  (00:40)\n",
      "45     0.014914    0.307936    0.936700  (00:40)\n",
      "46     0.015205    0.331237    0.933500  (00:40)\n",
      "47     0.014148    0.320758    0.937100  (00:40)\n",
      "48     0.010178    0.308162    0.937500  (00:40)\n",
      "49     0.007174    0.305438    0.940100  (00:40)\n",
      "50     0.006385    0.320493    0.937800  (00:40)\n",
      "51     0.006280    0.308098    0.938500  (00:40)\n",
      "52     0.005140    0.313937    0.938300  (00:40)\n",
      "53     0.003538    0.314670    0.939500  (00:40)\n",
      "54     0.002856    0.312398    0.941200  (00:40)\n",
      "55     0.002283    0.311956    0.943500  (00:40)\n",
      "56     0.002684    0.309670    0.942800  (00:40)\n",
      "57     0.001773    0.311642    0.941700  (00:40)\n",
      "58     0.001544    0.311899    0.941800  (00:40)\n",
      "59     0.001465    0.310673    0.942300  (00:40)\n",
      "60     0.001374    0.309457    0.942900  (00:40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 34 in FP32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 10:14\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.981860    1.655630    0.442400  (00:10)\n",
      "2      1.652082    1.412889    0.509100  (00:09)\n",
      "3      1.430169    1.261970    0.555100  (00:09)\n",
      "4      1.278686    1.132325    0.596700  (00:09)\n",
      "5      1.158788    1.041950    0.629000  (00:09)\n",
      "6      1.075928    0.964396    0.654400  (00:09)\n",
      "7      1.000220    0.895359    0.682300  (00:09)\n",
      "8      0.948396    0.856373    0.694500  (00:10)\n",
      "9      0.891566    0.813588    0.711600  (00:10)\n",
      "10     0.862627    0.788951    0.717100  (00:10)\n",
      "11     0.847679    0.746719    0.737100  (00:10)\n",
      "12     0.815115    0.730587    0.739800  (00:09)\n",
      "13     0.784083    0.711565    0.746500  (00:10)\n",
      "14     0.778181    0.703461    0.748900  (00:10)\n",
      "15     0.766937    0.679527    0.758100  (00:10)\n",
      "16     0.741391    0.669256    0.766900  (00:10)\n",
      "17     0.742755    0.666908    0.762600  (00:10)\n",
      "18     0.723425    0.661421    0.766000  (00:10)\n",
      "19     0.703250    0.652840    0.763500  (00:10)\n",
      "20     0.696448    0.645630    0.770500  (00:10)\n",
      "21     0.694999    0.633802    0.773500  (00:10)\n",
      "22     0.686297    0.644174    0.766500  (00:10)\n",
      "23     0.677074    0.618614    0.777800  (00:10)\n",
      "24     0.662021    0.627035    0.780400  (00:10)\n",
      "25     0.663618    0.609667    0.782100  (00:10)\n",
      "26     0.650291    0.604657    0.787400  (00:11)\n",
      "27     0.656044    0.608604    0.781400  (00:10)\n",
      "28     0.646843    0.596258    0.785000  (00:10)\n",
      "29     0.632837    0.596018    0.786500  (00:11)\n",
      "30     0.632080    0.593988    0.787700  (00:11)\n",
      "31     0.625402    0.585516    0.796500  (00:11)\n",
      "32     0.618845    0.591261    0.786600  (00:10)\n",
      "33     0.614307    0.580879    0.792900  (00:09)\n",
      "34     0.605446    0.576439    0.796800  (00:10)\n",
      "35     0.604895    0.579487    0.793400  (00:10)\n",
      "36     0.590471    0.574091    0.794600  (00:09)\n",
      "37     0.600014    0.570536    0.797300  (00:09)\n",
      "38     0.593319    0.569097    0.798500  (00:10)\n",
      "39     0.586024    0.569541    0.798700  (00:10)\n",
      "40     0.583915    0.569240    0.800100  (00:10)\n",
      "41     0.582220    0.566228    0.801100  (00:10)\n",
      "42     0.577236    0.564158    0.799900  (00:10)\n",
      "43     0.572053    0.558484    0.803400  (00:10)\n",
      "44     0.563389    0.558457    0.803200  (00:09)\n",
      "45     0.572046    0.555773    0.802800  (00:10)\n",
      "46     0.558610    0.555640    0.807300  (00:10)\n",
      "47     0.554288    0.554735    0.805300  (00:09)\n",
      "48     0.551956    0.558234    0.805000  (00:09)\n",
      "49     0.551951    0.559177    0.803800  (00:10)\n",
      "50     0.547740    0.557379    0.803800  (00:09)\n",
      "51     0.551195    0.552145    0.806000  (00:10)\n",
      "52     0.542024    0.553948    0.805800  (00:10)\n",
      "53     0.546074    0.552351    0.806200  (00:10)\n",
      "54     0.540950    0.549749    0.807000  (00:10)\n",
      "55     0.541382    0.550143    0.807200  (00:10)\n",
      "56     0.544482    0.552633    0.805600  (00:09)\n",
      "57     0.545111    0.554336    0.807600  (00:09)\n",
      "58     0.541079    0.551166    0.806700  (00:10)\n",
      "59     0.540118    0.552466    0.807800  (00:10)\n",
      "60     0.545251    0.550991    0.806900  (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 34 in FP16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 09:56\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.193574    1.740933    0.415300  (00:10)\n",
      "2      1.825156    1.493526    0.487800  (00:09)\n",
      "3      1.599781    1.338490    0.529700  (00:09)\n",
      "4      1.423133    1.218901    0.567200  (00:09)\n",
      "5      1.291676    1.119297    0.598700  (00:09)\n",
      "6      1.188651    1.045843    0.623500  (00:09)\n",
      "7      1.106800    0.980501    0.647000  (00:09)\n",
      "8      1.039319    0.919941    0.674200  (00:09)\n",
      "9      0.979433    0.885615    0.683700  (00:09)\n",
      "10     0.930135    0.827495    0.705400  (00:09)\n",
      "11     0.896852    0.812888    0.713000  (00:09)\n",
      "12     0.860437    0.773284    0.725600  (00:09)\n",
      "13     0.838502    0.754553    0.731600  (00:09)\n",
      "14     0.812123    0.740891    0.736000  (00:09)\n",
      "15     0.785818    0.719981    0.743400  (00:09)\n",
      "16     0.771483    0.701794    0.752300  (00:09)\n",
      "17     0.755891    0.699555    0.755300  (00:09)\n",
      "18     0.740510    0.688925    0.755900  (00:09)\n",
      "19     0.719554    0.672567    0.759800  (00:09)\n",
      "20     0.715873    0.660984    0.764800  (00:09)\n",
      "21     0.705073    0.653450    0.769900  (00:10)\n",
      "22     0.693323    0.646803    0.768900  (00:10)\n",
      "23     0.684470    0.630316    0.775500  (00:10)\n",
      "24     0.678831    0.628501    0.775100  (00:10)\n",
      "25     0.668792    0.623569    0.778400  (00:10)\n",
      "26     0.662028    0.618913    0.780200  (00:10)\n",
      "27     0.661580    0.618015    0.779700  (00:10)\n",
      "28     0.647033    0.615637    0.779900  (00:10)\n",
      "29     0.640682    0.604954    0.785100  (00:10)\n",
      "30     0.634142    0.599102    0.791100  (00:10)\n",
      "31     0.629744    0.597376    0.786800  (00:09)\n",
      "32     0.623828    0.593589    0.790500  (00:09)\n",
      "33     0.615781    0.595256    0.788800  (00:09)\n",
      "34     0.612943    0.591826    0.788200  (00:09)\n",
      "35     0.612059    0.588000    0.795600  (00:09)\n",
      "36     0.607055    0.584426    0.791700  (00:09)\n",
      "37     0.605625    0.583728    0.795500  (00:09)\n",
      "38     0.598512    0.576560    0.798500  (00:09)\n",
      "39     0.590476    0.579272    0.796400  (00:10)\n",
      "40     0.584570    0.575395    0.798500  (00:09)\n",
      "41     0.578727    0.573374    0.798200  (00:09)\n",
      "42     0.579479    0.573630    0.796900  (00:09)\n",
      "43     0.572794    0.573591    0.797300  (00:09)\n",
      "44     0.576100    0.567137    0.802400  (00:09)\n",
      "45     0.575225    0.568845    0.802000  (00:09)\n",
      "46     0.560995    0.568585    0.802200  (00:09)\n",
      "47     0.556113    0.566953    0.801900  (00:09)\n",
      "48     0.560829    0.566710    0.802900  (00:09)\n",
      "49     0.558713    0.562520    0.803500  (00:10)\n",
      "50     0.555512    0.564097    0.803800  (00:10)\n",
      "51     0.551499    0.564553    0.803700  (00:09)\n",
      "52     0.550851    0.565385    0.802800  (00:09)\n",
      "53     0.545920    0.563464    0.804000  (00:09)\n",
      "54     0.552296    0.564259    0.804000  (00:10)\n",
      "55     0.544195    0.563206    0.804300  (00:09)\n",
      "56     0.552889    0.562777    0.804000  (00:09)\n",
      "57     0.550492    0.562777    0.804700  (00:09)\n",
      "58     0.549609    0.562438    0.804200  (00:10)\n",
      "59     0.550801    0.561153    0.803000  (00:10)\n",
      "60     0.542272    0.562955    0.803400  (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50 in FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet50, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 16:08\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.790080    1.484671    0.486300  (00:18)\n",
      "2      1.490789    1.274267    0.553500  (00:14)\n",
      "3      1.292323    1.119700    0.604700  (00:14)\n",
      "4      1.127707    1.001376    0.647400  (00:14)\n",
      "5      1.034666    0.918210    0.677500  (00:15)\n",
      "6      0.933903    0.834426    0.703900  (00:15)\n",
      "7      0.858165    0.761041    0.729400  (00:16)\n",
      "8      0.802099    0.727623    0.743000  (00:16)\n",
      "9      0.748941    0.664229    0.766900  (00:16)\n",
      "10     0.711753    0.632384    0.782000  (00:16)\n",
      "11     0.673642    0.618663    0.784600  (00:16)\n",
      "12     0.644519    0.594132    0.793200  (00:16)\n",
      "13     0.635958    0.575863    0.800900  (00:16)\n",
      "14     0.606586    0.577193    0.799000  (00:16)\n",
      "15     0.579893    0.549878    0.805000  (00:16)\n",
      "16     0.582904    0.536953    0.810500  (00:16)\n",
      "17     0.567764    0.529449    0.817000  (00:16)\n",
      "18     0.550154    0.524807    0.819600  (00:16)\n",
      "19     0.543873    0.514189    0.820600  (00:16)\n",
      "20     0.534700    0.509078    0.823000  (00:16)\n",
      "21     0.519211    0.510663    0.826900  (00:16)\n",
      "22     0.508440    0.506179    0.824400  (00:16)\n",
      "23     0.506189    0.488410    0.828400  (00:16)\n",
      "24     0.503477    0.484065    0.832400  (00:16)\n",
      "25     0.487785    0.488729    0.829400  (00:15)\n",
      "26     0.466395    0.487107    0.830000  (00:15)\n",
      "27     0.471603    0.483711    0.832300  (00:15)\n",
      "28     0.464710    0.475865    0.833100  (00:15)\n",
      "29     0.450942    0.462025    0.840900  (00:16)\n",
      "30     0.449915    0.471631    0.836200  (00:16)\n",
      "31     0.434373    0.471360    0.837200  (00:15)\n",
      "32     0.436005    0.470550    0.836200  (00:15)\n",
      "33     0.440233    0.457505    0.843200  (00:15)\n",
      "34     0.413784    0.459619    0.841500  (00:15)\n",
      "35     0.414609    0.456184    0.843200  (00:15)\n",
      "36     0.418853    0.457553    0.844700  (00:16)\n",
      "37     0.401476    0.455204    0.845400  (00:16)\n",
      "38     0.393417    0.457695    0.841800  (00:16)\n",
      "39     0.386489    0.457494    0.844600  (00:16)\n",
      "40     0.384415    0.447332    0.848500  (00:15)\n",
      "41     0.390038    0.440008    0.851500  (00:16)\n",
      "42     0.374972    0.441870    0.848200  (00:16)\n",
      "43     0.369937    0.446398    0.848200  (00:16)\n",
      "44     0.362921    0.445450    0.850000  (00:16)\n",
      "45     0.362432    0.445790    0.850700  (00:16)\n",
      "46     0.360662    0.442684    0.848200  (00:16)\n",
      "47     0.363087    0.443592    0.849400  (00:16)\n",
      "48     0.347240    0.444308    0.847300  (00:16)\n",
      "49     0.350371    0.439712    0.851000  (00:17)\n",
      "50     0.348826    0.438959    0.851400  (00:16)\n",
      "51     0.343743    0.442053    0.852800  (00:15)\n",
      "52     0.340416    0.444644    0.851600  (00:15)\n",
      "53     0.333313    0.441120    0.852700  (00:15)\n",
      "54     0.336480    0.440341    0.851600  (00:15)\n",
      "55     0.331393    0.437596    0.852200  (00:15)\n",
      "56     0.336270    0.442075    0.851900  (00:15)\n",
      "57     0.328614    0.441448    0.852100  (00:15)\n",
      "58     0.333808    0.442888    0.852000  (00:16)\n",
      "59     0.338079    0.441546    0.852400  (00:15)\n",
      "60     0.330220    0.443260    0.851600  (00:15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50 in FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet50, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 14:20\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.925760    1.526584    0.473300  (00:20)\n",
      "2      1.629402    1.341644    0.532100  (00:13)\n",
      "3      1.422359    1.204565    0.577500  (00:14)\n",
      "4      1.269420    1.086304    0.619700  (00:14)\n",
      "5      1.149365    1.004452    0.648000  (00:14)\n",
      "6      1.052686    0.918193    0.671800  (00:14)\n",
      "7      0.962639    0.849272    0.698300  (00:14)\n",
      "8      0.895580    0.784770    0.719000  (00:14)\n",
      "9      0.832468    0.751411    0.733900  (00:14)\n",
      "10     0.786680    0.707686    0.753300  (00:14)\n",
      "11     0.737892    0.672041    0.765900  (00:14)\n",
      "12     0.698360    0.644888    0.776900  (00:14)\n",
      "13     0.675478    0.624919    0.785100  (00:14)\n",
      "14     0.648885    0.606992    0.790200  (00:14)\n",
      "15     0.629905    0.596147    0.795700  (00:14)\n",
      "16     0.603017    0.574590    0.803500  (00:14)\n",
      "17     0.592635    0.547783    0.810100  (00:14)\n",
      "18     0.578149    0.551960    0.811800  (00:14)\n",
      "19     0.563611    0.544691    0.811600  (00:14)\n",
      "20     0.544321    0.525536    0.821200  (00:14)\n",
      "21     0.533578    0.520834    0.818700  (00:14)\n",
      "22     0.520791    0.532493    0.816500  (00:14)\n",
      "23     0.517370    0.507134    0.822900  (00:14)\n",
      "24     0.506584    0.508283    0.826500  (00:14)\n",
      "25     0.488933    0.501615    0.828800  (00:14)\n",
      "26     0.482759    0.494965    0.832200  (00:14)\n",
      "27     0.480002    0.489091    0.831500  (00:14)\n",
      "28     0.474559    0.489551    0.833100  (00:14)\n",
      "29     0.457210    0.487825    0.836600  (00:14)\n",
      "30     0.454441    0.481079    0.837700  (00:14)\n",
      "31     0.445538    0.479356    0.837100  (00:14)\n",
      "32     0.435608    0.477265    0.838600  (00:14)\n",
      "33     0.438035    0.475249    0.840400  (00:13)\n",
      "34     0.428438    0.471538    0.841100  (00:14)\n",
      "35     0.420132    0.467988    0.841800  (00:14)\n",
      "36     0.421069    0.467993    0.840800  (00:14)\n",
      "37     0.410695    0.469155    0.843400  (00:14)\n",
      "38     0.403757    0.464651    0.843400  (00:14)\n",
      "39     0.396798    0.467730    0.842900  (00:14)\n",
      "40     0.394561    0.463377    0.844500  (00:14)\n",
      "41     0.382561    0.466172    0.844400  (00:14)\n",
      "42     0.382289    0.463652    0.847100  (00:14)\n",
      "43     0.375458    0.460753    0.847900  (00:14)\n",
      "44     0.373808    0.458588    0.846800  (00:14)\n",
      "45     0.370710    0.457078    0.850200  (00:14)\n",
      "46     0.363320    0.456902    0.850500  (00:14)\n",
      "47     0.357974    0.457647    0.849000  (00:14)\n",
      "48     0.354562    0.455026    0.850600  (00:14)\n",
      "49     0.354603    0.455654    0.849500  (00:14)\n",
      "50     0.343024    0.453958    0.849700  (00:14)\n",
      "51     0.339147    0.456858    0.852100  (00:14)\n",
      "52     0.336524    0.454960    0.850500  (00:14)\n",
      "53     0.337238    0.458226    0.850800  (00:14)\n",
      "54     0.340612    0.453605    0.851000  (00:14)\n",
      "55     0.341791    0.455858    0.850700  (00:14)\n",
      "56     0.334951    0.455281    0.850500  (00:14)\n",
      "57     0.334102    0.454167    0.849700  (00:14)\n",
      "58     0.331815    0.455067    0.850500  (00:14)\n",
      "59     0.333806    0.454659    0.851300  (00:14)\n",
      "60     0.335055    0.454645    0.850400  (00:14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 101 in FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet101, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 24:01\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.767628    1.496406    0.477800  (00:24)\n",
      "2      1.470542    1.274939    0.555500  (00:25)\n",
      "3      1.262356    1.126148    0.604800  (00:24)\n",
      "4      1.124002    1.010184    0.650700  (00:24)\n",
      "5      1.014872    0.897323    0.686500  (00:24)\n",
      "6      0.919713    0.830348    0.708700  (00:23)\n",
      "7      0.847648    0.774356    0.729700  (00:23)\n",
      "8      0.768236    0.709311    0.756100  (00:23)\n",
      "9      0.730965    0.667238    0.770800  (00:23)\n",
      "10     0.688476    0.645233    0.775000  (00:23)\n",
      "11     0.662864    0.612320    0.788600  (00:23)\n",
      "12     0.628203    0.610274    0.786600  (00:23)\n",
      "13     0.607273    0.582524    0.800000  (00:23)\n",
      "14     0.591641    0.557656    0.807100  (00:23)\n",
      "15     0.569198    0.561227    0.807400  (00:23)\n",
      "16     0.561833    0.545152    0.810100  (00:23)\n",
      "17     0.554600    0.531829    0.817800  (00:23)\n",
      "18     0.541353    0.551791    0.807200  (00:23)\n",
      "19     0.538480    0.533611    0.814700  (00:23)\n",
      "20     0.516670    0.513051    0.827100  (00:23)\n",
      "21     0.506338    0.503207    0.827800  (00:24)\n",
      "22     0.506567    0.523455    0.820100  (00:24)\n",
      "23     0.501290    0.507586    0.827800  (00:24)\n",
      "24     0.481037    0.505969    0.826800  (00:24)\n",
      "25     0.468110    0.498632    0.828200  (00:24)\n",
      "26     0.459258    0.492897    0.831000  (00:24)\n",
      "27     0.452679    0.494750    0.828200  (00:24)\n",
      "28     0.452317    0.507685    0.829700  (00:24)\n",
      "29     0.445049    0.484773    0.838300  (00:24)\n",
      "30     0.433333    0.492699    0.831200  (00:23)\n",
      "31     0.429784    0.472850    0.840200  (00:24)\n",
      "32     0.417665    0.483579    0.837700  (00:23)\n",
      "33     0.424226    0.465744    0.844500  (00:24)\n",
      "34     0.402243    0.461518    0.844700  (00:24)\n",
      "35     0.404785    0.465998    0.843100  (00:23)\n",
      "36     0.387398    0.461001    0.846000  (00:23)\n",
      "37     0.377826    0.457275    0.847900  (00:23)\n",
      "38     0.379646    0.459144    0.844700  (00:23)\n",
      "39     0.368736    0.453012    0.846100  (00:24)\n",
      "40     0.367683    0.456512    0.845500  (00:23)\n",
      "41     0.367488    0.459043    0.848800  (00:23)\n",
      "42     0.344834    0.455046    0.848600  (00:24)\n",
      "43     0.345105    0.451182    0.851100  (00:23)\n",
      "44     0.345998    0.453290    0.850200  (00:23)\n",
      "45     0.337941    0.451536    0.851700  (00:23)\n",
      "46     0.342986    0.446156    0.852100  (00:24)\n",
      "47     0.318387    0.451524    0.851900  (00:24)\n",
      "48     0.317093    0.452013    0.854600  (00:24)\n",
      "49     0.320584    0.451037    0.853500  (00:24)\n",
      "50     0.300236    0.452469    0.853300  (00:24)\n",
      "51     0.304716    0.450378    0.853100  (00:24)\n",
      "52     0.304964    0.449353    0.853900  (00:24)\n",
      "53     0.310274    0.443923    0.854000  (00:24)\n",
      "54     0.299720    0.446964    0.854400  (00:24)\n",
      "55     0.308363    0.448307    0.853400  (00:24)\n",
      "56     0.296214    0.447421    0.853500  (00:23)\n",
      "57     0.305482    0.447967    0.853100  (00:24)\n",
      "58     0.293255    0.446987    0.853600  (00:24)\n",
      "59     0.298422    0.450038    0.852900  (00:23)\n",
      "60     0.299199    0.446780    0.853400  (00:24)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 101 in FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet101, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 20:59\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.948015    1.562223    0.460400  (00:20)\n",
      "2      1.631433    1.358770    0.525600  (00:20)\n",
      "3      1.414180    1.210732    0.574700  (00:21)\n",
      "4      1.254014    1.088459    0.617500  (00:21)\n",
      "5      1.136890    1.005783    0.645800  (00:21)\n",
      "6      1.040242    0.928468    0.674000  (00:21)\n",
      "7      0.953884    0.849812    0.702400  (00:21)\n",
      "8      0.883903    0.791834    0.723100  (00:21)\n",
      "9      0.815515    0.750282    0.743000  (00:20)\n",
      "10     0.765203    0.704044    0.758200  (00:20)\n",
      "11     0.726844    0.673116    0.768900  (00:20)\n",
      "12     0.692003    0.643419    0.776500  (00:21)\n",
      "13     0.659547    0.611102    0.787600  (00:21)\n",
      "14     0.635328    0.607005    0.792900  (00:20)\n",
      "15     0.608404    0.589703    0.797500  (00:20)\n",
      "16     0.596698    0.572484    0.802400  (00:20)\n",
      "17     0.580117    0.556514    0.808700  (00:20)\n",
      "18     0.563573    0.555280    0.814300  (00:20)\n",
      "19     0.551752    0.538028    0.814200  (00:20)\n",
      "20     0.539180    0.553912    0.806800  (00:21)\n",
      "21     0.521730    0.535169    0.816300  (00:21)\n",
      "22     0.508628    0.538195    0.816300  (00:21)\n",
      "23     0.492176    0.519266    0.820500  (00:21)\n",
      "24     0.480458    0.501422    0.827000  (00:21)\n",
      "25     0.474871    0.516129    0.824600  (00:20)\n",
      "26     0.462025    0.507896    0.828700  (00:20)\n",
      "27     0.453516    0.501018    0.829500  (00:21)\n",
      "28     0.445166    0.499768    0.832400  (00:21)\n",
      "29     0.440408    0.482967    0.835700  (00:21)\n",
      "30     0.426444    0.492909    0.829500  (00:20)\n",
      "31     0.421484    0.490042    0.832700  (00:21)\n",
      "32     0.415318    0.484387    0.835100  (00:21)\n",
      "33     0.407449    0.481213    0.837600  (00:21)\n",
      "34     0.404577    0.477139    0.840000  (00:21)\n",
      "35     0.394441    0.480496    0.837000  (00:21)\n",
      "36     0.392785    0.475776    0.835800  (00:21)\n",
      "37     0.382236    0.480614    0.839300  (00:21)\n",
      "38     0.375946    0.475515    0.840900  (00:21)\n",
      "39     0.367682    0.482603    0.840600  (00:21)\n",
      "40     0.361108    0.477190    0.838700  (00:21)\n",
      "41     0.356192    0.474114    0.838500  (00:21)\n",
      "42     0.350969    0.473024    0.843700  (00:20)\n",
      "43     0.344451    0.468577    0.847000  (00:20)\n",
      "44     0.338316    0.472886    0.845000  (00:20)\n",
      "45     0.334081    0.473635    0.842800  (00:20)\n",
      "46     0.327903    0.475512    0.844500  (00:20)\n",
      "47     0.327244    0.473809    0.842200  (00:20)\n",
      "48     0.320010    0.472478    0.844600  (00:21)\n",
      "49     0.318628    0.472795    0.844100  (00:20)\n",
      "50     0.315376    0.471425    0.846600  (00:20)\n",
      "51     0.305834    0.471183    0.845700  (00:20)\n",
      "52     0.309484    0.470842    0.846200  (00:20)\n",
      "53     0.308582    0.474031    0.844000  (00:20)\n",
      "54     0.302808    0.473817    0.843800  (00:21)\n",
      "55     0.302723    0.470659    0.845200  (00:21)\n",
      "56     0.300376    0.473103    0.843800  (00:21)\n",
      "57     0.304317    0.472895    0.844200  (00:21)\n",
      "58     0.299435    0.472297    0.844300  (00:21)\n",
      "59     0.303945    0.473473    0.844800  (00:21)\n",
      "60     0.292447    0.471510    0.845400  (00:21)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 152 in FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet152, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 31:50\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.795876    1.442577    0.502500  (00:30)\n",
      "2      1.434135    1.211324    0.574500  (00:30)\n",
      "3      1.219598    1.054491    0.627500  (00:31)\n",
      "4      1.065201    0.925101    0.672400  (00:32)\n",
      "5      0.947252    0.835237    0.705300  (00:32)\n",
      "6      0.852417    0.769818    0.731300  (00:32)\n",
      "7      0.779233    0.701564    0.758700  (00:32)\n",
      "8      0.718954    0.643932    0.768700  (00:32)\n",
      "9      0.679028    0.611182    0.786300  (00:31)\n",
      "10     0.643206    0.726441    0.786100  (00:31)\n",
      "11     0.616436    0.553895    0.808500  (00:31)\n",
      "12     0.599687    0.566333    0.802800  (00:31)\n",
      "13     0.569029    0.539677    0.814800  (00:31)\n",
      "14     0.541109    0.512112    0.825000  (00:31)\n",
      "15     0.535076    0.500172    0.824700  (00:32)\n",
      "16     0.525116    0.509861    0.819600  (00:31)\n",
      "17     0.514518    0.501379    0.826300  (00:31)\n",
      "18     0.499004    0.497418    0.826500  (00:32)\n",
      "19     0.488863    0.494906    0.829700  (00:31)\n",
      "20     0.487894    0.490766    0.830400  (00:31)\n",
      "21     0.465174    0.489985    0.826800  (00:32)\n",
      "22     0.458297    0.464463    0.839400  (00:32)\n",
      "23     0.455674    0.467351    0.840700  (00:32)\n",
      "24     0.444815    0.470728    0.841100  (00:32)\n",
      "25     0.427426    0.466688    0.842500  (00:32)\n",
      "26     0.425568    0.458552    0.844800  (00:33)\n",
      "27     0.410889    0.469711    0.838900  (00:32)\n",
      "28     0.402253    0.446540    0.847600  (00:31)\n",
      "29     0.395283    0.455860    0.847300  (00:31)\n",
      "30     0.396584    0.460360    0.846700  (00:31)\n",
      "31     0.388792    0.450494    0.845500  (00:31)\n",
      "32     0.372679    0.452639    0.846300  (00:32)\n",
      "33     0.363353    0.444020    0.851400  (00:32)\n",
      "34     0.369944    0.442028    0.847100  (00:33)\n",
      "35     0.360623    0.445900    0.848000  (00:32)\n",
      "36     0.348216    0.439558    0.853500  (00:31)\n",
      "37     0.351438    0.438912    0.851300  (00:31)\n",
      "38     0.332254    0.443077    0.853300  (00:32)\n",
      "39     0.331061    0.436232    0.852900  (00:31)\n",
      "40     0.323548    0.430805    0.855100  (00:32)\n",
      "41     0.311399    0.436791    0.856200  (00:32)\n",
      "42     0.305470    0.441321    0.853600  (00:31)\n",
      "43     0.299548    0.439048    0.856100  (00:31)\n",
      "44     0.291739    0.430488    0.857600  (00:31)\n",
      "45     0.281873    0.439410    0.858100  (00:32)\n",
      "46     0.281518    0.429479    0.858400  (00:32)\n",
      "47     0.277296    0.435277    0.856900  (00:32)\n",
      "48     0.273812    0.432929    0.856900  (00:31)\n",
      "49     0.263448    0.434873    0.860200  (00:31)\n",
      "50     0.259212    0.437491    0.858000  (00:31)\n",
      "51     0.257610    0.435388    0.857100  (00:31)\n",
      "52     0.257956    0.436554    0.856000  (00:31)\n",
      "53     0.251937    0.434741    0.857600  (00:31)\n",
      "54     0.254876    0.438379    0.857700  (00:31)\n",
      "55     0.251244    0.434156    0.860700  (00:31)\n",
      "56     0.246060    0.435735    0.859100  (00:31)\n",
      "57     0.243881    0.435492    0.859500  (00:31)\n",
      "58     0.248854    0.435000    0.858800  (00:31)\n",
      "59     0.245510    0.432876    0.859900  (00:31)\n",
      "60     0.244345    0.434481    0.860400  (00:31)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 152 in FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=bs).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet152, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 25:58\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.911248    1.496594    0.478800  (00:25)\n",
      "2      1.581300    1.275785    0.554700  (00:26)\n",
      "3      1.357416    1.121515    0.609300  (00:26)\n",
      "4      1.191497    1.019990    0.641000  (00:26)\n",
      "5      1.073234    0.926011    0.674500  (00:25)\n",
      "6      0.966677    0.839877    0.704300  (00:25)\n",
      "7      0.880152    0.776991    0.724100  (00:26)\n",
      "8      0.807180    0.717119    0.747800  (00:26)\n",
      "9      0.744560    0.680570    0.759500  (00:26)\n",
      "10     0.704918    0.644767    0.775300  (00:25)\n",
      "11     0.661834    0.615626    0.786200  (00:26)\n",
      "12     0.630952    0.573346    0.800500  (00:26)\n",
      "13     0.600699    0.559540    0.808100  (00:26)\n",
      "14     0.579632    0.558865    0.808900  (00:25)\n",
      "15     0.557303    0.549953    0.810800  (00:26)\n",
      "16     0.535317    0.527162    0.816700  (00:26)\n",
      "17     0.523816    0.500287    0.826800  (00:26)\n",
      "18     0.508728    0.520647    0.824200  (00:26)\n",
      "19     0.495821    0.510365    0.826000  (00:26)\n",
      "20     0.480800    0.492571    0.831800  (00:25)\n",
      "21     0.470582    0.492453    0.831500  (00:25)\n",
      "22     0.458488    0.479146    0.834600  (00:25)\n",
      "23     0.449489    0.488275    0.833000  (00:25)\n",
      "24     0.435596    0.473281    0.838400  (00:25)\n",
      "25     0.432515    0.468738    0.841100  (00:26)\n",
      "26     0.417014    0.452228    0.845400  (00:26)\n",
      "27     0.409394    0.467385    0.840700  (00:26)\n",
      "28     0.402565    0.463613    0.842100  (00:26)\n",
      "29     0.390225    0.462767    0.843100  (00:26)\n",
      "30     0.376939    0.455731    0.846500  (00:26)\n",
      "31     0.374270    0.455840    0.848600  (00:26)\n",
      "32     0.371016    0.453200    0.846800  (00:26)\n",
      "33     0.356549    0.453408    0.845900  (00:26)\n",
      "34     0.354372    0.454507    0.845500  (00:26)\n",
      "35     0.344786    0.441083    0.851200  (00:26)\n",
      "36     0.338408    0.446611    0.849600  (00:26)\n",
      "37     0.332722    0.452798    0.847100  (00:26)\n",
      "38     0.327156    0.443086    0.850400  (00:26)\n",
      "39     0.314871    0.449781    0.850200  (00:26)\n",
      "40     0.308188    0.450745    0.851900  (00:26)\n",
      "41     0.305967    0.444580    0.851000  (00:26)\n",
      "42     0.300071    0.450265    0.851700  (00:25)\n",
      "43     0.296721    0.449878    0.853500  (00:25)\n",
      "44     0.290904    0.456749    0.850300  (00:25)\n",
      "45     0.284132    0.451935    0.853300  (00:25)\n",
      "46     0.277966    0.461513    0.848300  (00:25)\n",
      "47     0.271881    0.451641    0.852600  (00:25)\n",
      "48     0.273040    0.452864    0.852000  (00:25)\n",
      "49     0.267372    0.454419    0.855000  (00:25)\n",
      "50     0.264705    0.450830    0.855600  (00:25)\n",
      "51     0.257351    0.449708    0.855100  (00:25)\n",
      "52     0.252709    0.450875    0.855600  (00:25)\n",
      "53     0.254813    0.453019    0.855500  (00:25)\n",
      "54     0.245248    0.451623    0.855300  (00:25)\n",
      "55     0.248092    0.452689    0.855100  (00:25)\n",
      "56     0.247010    0.450188    0.855400  (00:25)\n",
      "57     0.243452    0.453587    0.853400  (00:25)\n",
      "58     0.248346    0.452661    0.853400  (00:25)\n",
      "59     0.249157    0.452330    0.854400  (00:26)\n",
      "60     0.245193    0.453021    0.854000  (00:25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gpu_mem_restore_ctx():\n",
    "    learn.fit_one_cycle(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
